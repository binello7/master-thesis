\chapter{Introduction}
\label{chp:introduction}
%-------------------------------------------------------------------------------

% Define some commands to keep the formatting separated from the content 
\newcommand{\keyword}[1]{\textbf{#1}}
\newcommand{\tabhead}[1]{\textbf{#1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\file}[1]{\texttt{\bfseries#1}}
\newcommand{\option}[1]{\texttt{\itshape#1}}
%-------------------------------------------------------------------------------
% Introduction
% * 1-2 pages long
% * 




%-------------------------------------------------------------------------------
%Really needed? 

%Probably go directly to emulation:

%need for prediction => accurate/detailed simulators => computationally expensive => emulator for prediction in (near) real-time.

%Explain emulation (general) => emulation in hydrology (very/briefly).
%=> what is not known/which problem does this thesis solve?

%=> can be focused on flood prediction, 2D models, open source (Fullswof-emulator) => understanding of mechanistic /phenomenological emulators in hydrology/flood prediction, ...

%=> choose the problem where YOU can say the most.
%-------------------------------------------------------------------------------
%-------------------------------------------------------------------------------
%can also be done manually.

%In an Emulation context, Likelihood-based parameter estimation is probably the thing to advocate. Not just an (arbitrary) objective function, but a mathematical description of "the data generating process", i.e. a stochastic model, which encodes information on the mathematical abstraction of the physical processes (rainfall-runoff) and the observation process(es), e.g. rainfall, land cover, soil moisture, flow.
%-------------------------------------------------------------------------------
%-------------------------------------------------------------------------------
%Pappenberger /Beven 2006
%-------------------------------------------------------------------------------
%-------------------------------------------------------------------------------
%detailed (and presumably accurate) simulators, such as 2D runoff models, 
%-------------------------------------------------------------------------------
%predictions, i.e. thousands of runs for quantitative estimates of prediction uncertainty.
%-------------------------------------------------------------------------------
%-------------------------------------------------------------------------------
%Introduce the following section "Emulation", a brief introduction about emulation
%-------------------------------------------------------------------------------
%-------------------------------------------------------------------------------


Flooding and inundation might become more frequent and severe in many regions of Europe due to climate change.
Studies show, that although a global tendency to drier summers, increase in extreme rain events, able to trigger severe flooding, is very likely in many areas of Europe \autocite{christensen_severe_2002}.
In mountainous regions like the Alps, the ratio of liquid to solid precipitations are certainly going to change, altering the nature and processes of floods.
The direct consequence is an anticipated seasonal shift in precipitation, causing precipitations increase in winter. 
This seasonal shift in precipitation, accompanied by the earlier snowmelt, is likely to alter runoff behaviour and flood generation.
In particular, a seasonal change in the distribution of floods is expected \autocite{koplin_seasonality_2014}.
These changes are likely to make our capability to predict occurrence and effects of flooding more unreliable.

To limit risks and damage, being able to correctly predict flooding is of crucial importance.
With the everyday growing data availability and computational power, and the development of more sophisticated and accurate simulators, simulation offers a valid and very powerful tool for making hydrological predictions.
Numerical models of entire catchments can be built, where depending on accuracy required and the time scale used different processes such as infiltration, evapotranspiration, interception surface runoff and erosion can be implemented.
However, for these very complex tools there is a price to pay: their computational cost is very high.
The duration of a single simulation can vary from some minutes up to days or even weeks.

\emph{Emulation}, the construction of simpler approximation models mimicking the behaviour of complex simulator, is one way to deal with the problem.
{Emulators}, also referred as "surrogate models", are ad hoc data-driven approximation models that are much cheaper to evaluate.
These, when properly constructed, can accurately reproduce the behaviour of the simulator based on which they were built \autocite{gorissen_surrogate_2010}.



curate models can be achieved. These models are mainly based on topographical
data of the catchment in question, which are then refined by assigning friction coef-
ficients values, infiltration capacity values, hydraulic conductivity values, porosity
values to the different zones of the catchment. Such models need to be calibrated.





Depending on the degree of detail chosen more or less accurate models can be achieved.
These models are mainly based on topographical data of the catchment in question, which are then refined by assigning friction coefficients values, infiltration capacity values, hydraulic conductivity values, porosity values to the different zones of the catchment.
Such models need to be calibrated.
This means that by using optimization algorithms the parameters of the model are varied within certain ranges in order to reproduce at best a recorded output (e.g. river outlet hydrograph) generated from "known" initial conditions (e.g. initial soil saturation) and inputs (e.g. the recorded hyetograph).
Once the model is calibrated it can be used to generate new data, from which new information about the given system can be learned and from which other conditions and new situations can be tested.

The main drawback of simulation lays in its very high computational burden.
For calibration alone several runs of the model are required.
Every simulation can last from some minutes up to several hours, depending on the complexity of the model, the type of computer where the simulations are run, the duration of the event simulated, the resolution used for the model, etc.
Once the model is calibrated several more runs are necessary in order to generate the desired dataset.
The number of runs depends on the kind of study one would like to carry out.
For uncertainty analysis for example, up to some thousands of simulations can be run, in order to study the influence that the variation of a parameter of the model (or its uncertain determination) has on the output.\\




% ------------------------------------------------------------------------------
% ================================================================================
\section{Definition of goals}
% ================================================================================

Focus on emulation subject.

\begin{itemize}
\itemsep0em
  \item explain what is emulation
  \item use both terms \textit{surrogate model} and \textit{emulator}
  \item mention \textit{EmuMore} project
  \item give emulation examples
\end{itemize}


% ==============================================================================
\section{Emulation}
% ==============================================================================

\begin{itemize}
\itemsep0em
  \item define the goals of this thesis
  \item state the questions which should be answered withing this thesis. Try to close the loop in the conclusions chapter (cf. Thesis example JÃ¶rg)
  \item what readers should expect from the thesis
  \item mention reproducibility, open softwares
  \item include a scheme with the \emph{emulation workflow}
\end{itemize}








